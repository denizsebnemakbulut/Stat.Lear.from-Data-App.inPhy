{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879ccb4e-30cc-4679-83d4-5f398e5a6849",
   "metadata": {},
   "source": [
    "### Importing required libraries modules and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8df310-67b5-4ba8-8e48-1f75b4bb1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dfe50-3de1-4166-8c33-be0437a379c6",
   "metadata": {},
   "source": [
    "### Loading MNIST Dataset\n",
    "\n",
    "We are doing binary classification, so we need only 1 and 0 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ba947e-4d2b-48e3-bb6e-11b9ee3ebdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data = datasets.MNIST('./data/anupam-data/pytorch/data/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_data = datasets.MNIST('./data/anupam-data/pytorch/data/', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "subset_indices = ((train_data.train_labels == 0) + (train_data.train_labels == 1)).nonzero().view(-1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False,\n",
    "                                           sampler=SubsetRandomSampler(subset_indices)\n",
    "                                          )\n",
    "\n",
    "subset_indices = ((test_data.test_labels == 0) + (test_data.test_labels == 1)).nonzero().view(-1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          sampler=SubsetRandomSampler(subset_indices)\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a681502-9f8a-41fb-bcc6-e9d9431b9e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy with SGD optimizer without regularization: 97.163124 %\n",
      "Logistic Regression Accuracy with SGD optimizer with regularization: 99.101654 %\n",
      "Logistic Regression Accuracy with Adam optimizer without regularization: 99.243500 %\n",
      "Logistic Regression Accuracy with Adam optimizer with regularization: 99.385345 %\n",
      "Support Vector Machine Accuracy with SGD optimizer without regularization: 99.338058 %\n",
      "Support Vector Machine Accuracy with SGD optimizer with regularization: 99.432625 %\n",
      "Support Vector Machine Accuracy with Adam optimizer without regularization: 99.290779 %\n",
      "Support Vector Machine Accuracy with Adam optimizer with regularization: 99.763596 %\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 64\n",
    "input_size = 784  #(dimension of image 28 * 28)\n",
    "num_classes = 1   #(just -1 and 1 image)\n",
    "learning_rate = 0.0001 ## step size used by SGD \n",
    "momentum = 0.015 ## Momentum is a moving average of our gradients (helps to keep direction)\n",
    "\n",
    "class Regress_Loss(nn.modules.Module):    \n",
    "    def __init__(self):\n",
    "        super(Regress_Loss,self).__init__()\n",
    "    def forward(self, outputs, labels):\n",
    "        batch_size = outputs.size()[0]\n",
    "        return torch.sum(torch.log(1 + torch.exp(-(outputs.t()*labels))))/batch_size\n",
    "\n",
    "class SVM_Loss(nn.modules.Module):    \n",
    "    def __init__(self):\n",
    "        super(SVM_Loss,self).__init__()\n",
    "    def forward(self, outputs, labels):\n",
    "         return torch.sum(torch.clamp(1 - outputs.t()*labels, min=0))/batch_size\n",
    "        \n",
    "\n",
    "#Logistic regression model and Loss\n",
    "\n",
    "models = [Regress_Loss(), SVM_Loss()]\n",
    "\n",
    "\n",
    "\n",
    "for j in range(8):\n",
    "\n",
    "    logistics_model = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    optimizers = [torch.optim.SGD(logistics_model.parameters(), lr=learning_rate, weight_decay = 0),\n",
    "                  torch.optim.SGD(logistics_model.parameters(), lr=learning_rate, weight_decay = 1),\n",
    "                  torch.optim.Adam(logistics_model.parameters(), lr=learning_rate, weight_decay = 0),\n",
    "                  torch.optim.Adam(logistics_model.parameters(), lr=learning_rate, weight_decay = 1),\n",
    "                  torch.optim.SGD(logistics_model.parameters(), lr=learning_rate, weight_decay = 0),\n",
    "                  torch.optim.SGD(logistics_model.parameters(), lr=learning_rate, weight_decay = 1),\n",
    "                  torch.optim.Adam(logistics_model.parameters(), lr=learning_rate, weight_decay = 0),\n",
    "                  torch.optim.Adam(logistics_model.parameters(), lr=learning_rate, weight_decay = 1)]\n",
    "    \n",
    "    if j <= 3:\n",
    "        loss_criteria = models[0]\n",
    "\n",
    "    else:\n",
    "        loss_criteria = models[1]\n",
    "    \n",
    "    optimizer = optimizers[j]\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, 28*28)            \n",
    "        labels = Variable(2*(labels.float()-0.5))\n",
    "\n",
    "        outputs = logistics_model(images)               \n",
    "        loss = loss_criteria(outputs, labels)    \n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "\n",
    "    # Test the Model\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        outputs_test = torch.sigmoid(logistics_model(images))\n",
    "        \n",
    "        predicted = outputs_test.data >= 0.5 \n",
    "\n",
    "        total += labels.size(0) \n",
    "\n",
    "        correct += (predicted.view(-1).long() == labels).sum()\n",
    "      \n",
    "    if j == 0:\n",
    "        print('Logistic Regression Accuracy with SGD optimizer without regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 1:\n",
    "        print('Logistic Regression Accuracy with SGD optimizer with regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 2:\n",
    "        print('Logistic Regression Accuracy with Adam optimizer without regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 3:\n",
    "        print('Logistic Regression Accuracy with Adam optimizer with regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 4:\n",
    "        print('Support Vector Machine Accuracy with SGD optimizer without regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 5:\n",
    "        print('Support Vector Machine Accuracy with SGD optimizer with regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    elif j == 6:\n",
    "        print('Support Vector Machine Accuracy with Adam optimizer without regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    else:\n",
    "        print('Support Vector Machine Accuracy with Adam optimizer with regularization: %f %%' % (100 * (correct.float() / total)))\n",
    "    \n",
    "    logistics_model.reset_parameters()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e01db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
